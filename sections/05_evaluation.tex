\section{Evaluation}

\subsection{Technical}

\subsubsection{Key safety}

At the heart of the security model of this application lies the underlying security of Ethereum's (and more generally blockchain) security model and the security of the cryptography scheme used for encryptions.

\paragraph{User-held keys}

A fundamental issue with creating a decentralised system, certainly under the proposed implementation, is the issue of private key storage. Without a central authority managing the identities within the system each user is expected to securely store their keys. Failure to do so will result in account compromises possibly including corruption of data, changing of permissions, and taking control of an identity's contract. Owing to the transaction history available through a blockchain, previous data references are recoverable in the event of a compromise.

However, if a user loses either of their keys (identity or encryption) there are serious consequences.

If a user loses their identity key, it is impossible to prove that they own the address. This means that they would no longer have any control over their contract(s) with current permissions remaining and irrevokable. The user would not be able to share any further content or upload any references to content that they owned. Only a local (non-blockchain) record of all their data references would allow them to retrieve their data.

At this point I consider a possible solution to the problem of losing the identity key. If a future implementation allowed the user to delegate certain identities as privileged on their contract(s) it might be possible to regain access. These privileged identities would be able to form a quorum which would allow the transfer of a contract's properties to another, new, contract with a new identity. The practical implementation of this would be difficult, and it is likely that the transaction history of the original contract could not be maintained by the new contract.

If a user loses their encryption key, they are unable to directly decrypt data. With the implementation proposed there is no mechanism for them to recover their data other than through collusion with other identities with whom they have shared their data. Taking a similar stance to the identity key loss problem above, creating backup encryption keys which are given full access to the data in one's contract, and allowing the use of these under a quorum of privileged users would be a possible solution to the encryption key loss problem. In this scenario, there is a slight security loss, but this is negligible in practice.

\paragraph{Identity Spoofing}

Under the current implementation, access to one's storage contracts or group contracts are determined by the identity of their key. Every account (address) on an Ethereum network is a 20 byte value. These 20 bytes represent the last 20 bytes of the SHA-3 (Keccak) hash of the public key of the account holder. This public key is the counterpart to a 256-bit ECDSA private key which is used to unlock the account and sign transactions. An example of this derivation is found in table \ref{table:ethereum_ecdsa_address_derivation}.

\input{figures/ethereum_ecdsa_address_derivation}

The major concern for this system is identity spoofing. If a party has access to the private key associated with a specific ethereum address

Given that the ethereum address associated with any private key is 20 bytes, this gives $2^{160}$ possible addresses in the system. This means the probability of
guessing your address is extremely low ($6.8 \times 10^{-49}$). Whilst an identity's address can be public, this in itself provides a layer of obscurity.

With the public key is hashed, unless the user chooses reveal it, the public key remains private under the security provided by the given hash function. Therefore, no attacker gains (with respect to the challenge of acquiring the private key associated with an address) from knowing your address.

The 256-bit private key provides the main layer of security for an identity. With $2^{256}$ possible key values, the challenge of determining the private key corresponding to a public key (or identity's address) is hard. For each key possibility, the key must be used to generate a public key, which is hashed and the last 20 bytes compared. This is what will be referred to as a key check. Using a python script~\footnote{10,000 iterations of checking a private key against an address. Uses script in program code \ref{code:secp256k1_benchmark} (Appendix)} on a modern laptop~\footnote{MacBook Pro 13-inch. OS X 10.12.5. Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz. 8GB RAM.} with floating point performance of the order of 3.46 GFLOPS/s per core, a rate of 120 key checks per second can be achieved. On average $2^{255}$ tries will be required to produce the correct key.

$$
2^{255} \div (120 \times 3600 \times 24 \times 365) = 1.53 \times 10^{67} \text{ years}
$$

As of June 2016, the fastest supercomputers in the world have a potential of roughly 100 PFLOPS ($10^8$ GFLOPS)~\footnote{China builds world's fastest supercomputer.  \href{http://www.computerworld.com/article/3085483/high-performance-computing/china-builds-world-s-fastest-supercomputer-without-u-s-chips.html}{\textit{Computer World}}}. Even so, using current chipsets it would still take $10^{59}$ years to find the private key.

$$
1.53 \times 10^{67} \div (10^8 \div 3.46) = 5.29 \times 10^{59} \text{ years}
$$

Whilst computed using commodity hardware and an unoptimised script, the calculations shown illustrate the difficulty of determining and checking a 256-bit ECDSA (secp256k1) key against a known Ethereum address.

\paragraph{Breaking Data Encryption}

Stored on IPFS, the so-called 'permanent web', the quality of the encryption of personal data is of pivotal importance. The scheme uses a randomly generated symmetric key to encrypt the underlying data, which is itself encrypted by a user-specific public key. In this regard, a malicious attacker would have to either find the symmetric key or find the public key that unlocks the encrypted symmetric key. These challenges are defined by the security of the cryptography scheme and the key size used. For this project a 256-bit AES key and a 256-bit ElGamal key.

We assume that the underlying encryption is secure and that vulnerabilities are concerned with key leaks. This means that we do not consider cryptographic 'breaks', only that a key is found by brute force.

Fundamentally, there are $2^{256}$ possible keys to check against either the symmetric or asymmetric cryptography schemes. Assuming no information is given away by the public key of the asymmetric scheme, both schemes are equally secure requiring $2^{255}$ or $~5.8 \times 10^{76}$ trials to determine the key on average. Assuming a supercomputer has 100 petaflops and that this is a suitable measure of performance, it can generate $10^{17}$ keys per second. It will take $1.84 \times 10^{52}$ years on average to generate a suitable key for an encryption under a 256-bit scheme~\footnote{Not including the time taken to perform a decryption on a suitably small test encryption.}.

$$
\begin{aligned}
  10^{17} \times 3.6 \times 10^{3} \times 24 \times 365 &=& 3.1536 \times 10^{24} \text{ keys per year} \\
  \frac{2^{255}}{3.1536 \times 10^{24}} &=& 1.84 \times 10^{52} \text{ years}
\end{aligned}
$$

\subsubsection{Non-transitivity of a Re-encryption scheme}

In order to facilitate giving permissions to other parties the scheme only uses second-level encryptions. The most significant security implication of using second-level encryptions instead of a first-level encryption is that of re-encryption and delegation. With a second-level encryption, since the underlying data is encrypted using a public key, a suitable pairing and a suitable re-encryption key provides the means for any second-level encryption to be re-encrypted as a first-level encryption. Since a first-level encryption uses a bi-linear pairing of keys to encrypt the underlying data, this is not re-pairable and as such re-encryption cannot be performed. Given that a second-level encryption can be re-encrypted to a first-level encryption, and that a first-level encryption is not re-encryptable, the AFGH scheme used is shown to be non-transitive.

Non-transitivity is an extremely important property of this scheme. An entity $A$ encrypts their data $d$ with their public key such that it becomes $d_A$. $A$ produces a re-encryption key $re_{A \rightarrow B}$ for some other entity $B$. $B$ has previously created a re-encryption key $re_{B \rightarrow C}$ such that another entity $C$ is able to read their data. We assume both re-encryption keys are public, or at least both available to $C$ (possibly through collusion with the proxy). With a transitive scheme, entity $C$ would be able to use $re_{A \rightarrow B}$ and $re_{B \rightarrow C}$ to re-encrypt any $d_A$ to $d_C$, bypassing the permission of $A$ entirely.

In the non-transitive scheme, revealing $re_{A \rightarrow B}$ to $C$ bears no security implication. Whilst $C$ is able to create a first-level encryption for $B$, $C$ is none-the-wiser to the underlying data that $A$ has encrypted in $d_A$.

\subsubsection{Data security given public re-encryption keys}

Having considered why re-encryption keys can be public in terms of the security of single data blobs, we must evaluate the effects of this over multiple data blobs.

One criticism of the implemented scheme is that should an identity $I$ have read access to a storage contract owner's file $F_A$, they have the means to read any of said storage contract owner's files encrypted under the same key. They achieve this by finding a reference to the file they wish to read and, using the re-encryption key $re_{\text{SCO} \rightarrow \text{I}}$ that they already possess, they are able to re-encrypt the file into a first-level encryption under their own public key.

It is my opinion that this is one of the greatest flaws of the project's current implementation and represents a challenge to solve it. Assuming that proxy re-encryption is secure and allows public re-encryption keys for singular stores, expanding this over multiple stores or stores with multiple data blobs might imply that a separate key is required for each data blob. If this is the case, the storage required to store keys and the responsibility on the user at a practical level makes for an application unlikely to succeed.

Should each individual blob have its own key, it might be possible that a re-encryption key is generated to allow the reading of the private key by the storage contract owner's key for the purposes of generating re-encryption keys. Users could then use the public key of the data blob to encrypt data, and have a data blob-specific re-encryption key. The problem here is that the key store size (on IPFS) grows with the number of data blobs. At present the size of the re-encryption key store is of space complexity $O(n)$ where $n$ is the number of read shares. If $m$ is the number of data blobs shared, and we assume all data blobs are shared with the exact same $n$ identities, then the re-encryption key store grows in $O(m \times n)$.

Crucially, a user of the application doesn't not want to hold their own keys. The application enforces that they must hold at least two keys (identity and encryption keys) for the system to function. Any need for a user to hold more keys than this is a problem. At present, there is no way to store secrets within the public blockchain, and with this restriction the security implications as discussed above are likely to remain in a completely decentralised system, at least with optimal key storage.

\subsubsection{The need for a proxy}

As the name would suggest proxy re-encryption is designed to be used by three parties, Alice, Bob, and a semi-trusted proxy. The role of the proxy is to perform re-encryption. Given that the AFGH scheme is both collusion-safe and non-transitive, we must consider the benefit that a proxy would give us, and also the compromise it requires.

Firstly, it's easy to see that the requirement of a proxy, a centralised service no less, somewhat inhibits the idea of a fully decentralised system. In fact, if a proxy is required for read access by every party other than the storage contract owner, then should the proxy cease to exist or be inoperable, access is denied to all persons other than the storage contract owner. Given the use case of the NHS, this might imply that doctors would be unable to access patient records or other data when a denial of service attack is taking place.

It is important to note that a denial of service on a blockchain is not impossible, and in fact flooding the network with transactions has this effect. It is however less potent since the compute power is distributed across many hundreds and thousands of completely independent nodes.

Considering the benefits of a proxy, a system whereby the proxy is authenticated and authorised with special privileges stops the re-encryption key (and the encrypted, stored data) from needing to exist publicly. Such a proxy would be authorised to perform re-encryption and check the permissions of an identity against a storage contract. The proxy would take a request from an identity, and assuming they had the necessary permissions and provided sufficient proof-of-identity, would return the requested data as a first-level encryption under the identity's public key. By performing in this way the proxy would prevent the re-encryption key or the storage reference ever being revealed and therefore removes the issue presented above with regards to overuse of the re-encryption key.

\paragraph{Is re-encryption possible client-side?}

Through the project a difficult choice had to be made. It was possible to use a scheme predating the AFGH scheme such as the scheme authored by \cite{bbs:1998:book}, rather than using the AFGH scheme for which there is no suitable javascript implementation. However, in using such a scheme, the security properties of the AFGH scheme would be lost, rendering the implementation of the project old fashioned and out of date before it could be improved. Instead of using an unsuitable scheme, an API which, at present, must be run on the client device was implemented using the existing Java library.

The use of this API is a key barrier to the decentralisation and global adoption across devices and should be thought of as a major issue. However, it also allowed the conclusion of a successful investigation into the project viability. An implementation of a client-side (likely JavaScript) library is required for future iterations.

\subsubsection{Privacy of contract information and state}

Since this project's core goal is to reinstate the privacy so many honest actors in society have lost through corporate activity, it would be irresponsible to conclude without discussing the public nature of all data placed on Ethereum. Using any public, and permission-less, blockchain technology implies that all transactional data is exposed and made public. Program code \ref{code:view_storage_data} (Appendix) shows this by creating a contract, setting a value, and then exposing that value through a transaction.

Clearly the nature of data being public implies that one can be tracked through their transactions. For our purposes, this transparency exposes corporations interacting with the blockchain. Whether it benefits individuals overall or not is ambiguous. However, the privacy of the underlying data exchanged on a blockchain doesn't have to be compromised, provided no actual data itself is stored in an unencrypted form. Furthermore, only providing references on the blockchain implies that the permissions associated with a given data blob are decided, to some extent, off the chain and there is little to no benefit to having the reference if you have no permissions or ability to read the underlying content.

\subsubsection{Monetisation}

At present, the transaction costs associated with using Ethereum have not been considered. During development of an example implementation these were ignored wherever possible. In a production environment this would not be possible, and it's important to consider how the project would work from this point of view.

An important part of any chain's development is how transactions are funded as a means of market making between the transaction producer and consumer, the buyer and seller respectively. Most blockchains choose to either provide their own currency or tokenise one already available. For this application it must be evaluated further, given user data, to determine user trends and how might be best to optimise the contracts to reduce excessive transaction costs.

It may be possible to use a mixture of current chains and arbitrate between their differing transaction costs, using a service such as Polkadot, authored by \cite{polkadot:2017:online}. In this way, two chains offering different transaction costs could be used such that transactions are committed on the chain with the least cost, and transfers are handled by the chain arbitration technology. The technology to be able to do this is not yet available, but is likely to be available within the next few years.

\subsubsection{Security by obscurity}

Data stored on IPFS is permission-less, i.e. it is accessible by anyone~\footnote{Anyone can access any hash, such as QmWATWQ7fVPP2EFGu71UkfnqhYXDYH566qy47CnJDgvs8u, from the gateway or an IPFS client. \href{https://gateway.ipfs.io/ipfs/QmWATWQ7fVPP2EFGu71UkfnqhYXDYH566qy47CnJDgvs8u}{\textit{IPFS Gateway}}}. There are two components to keeping the data secure, obscurity and encryption. The latter is the responsibility of the IPFS user, but the former is decided by the hash function.

IPFS uses a multi-hash system, with SHA-256 being used at present (hence Qm prefixing any current base58 IPFS hash). IPFS is mostly concerned with avoiding collision hashes such that a history of all data is maintained, but this has a secondary security effect of preventing guessing where data lives unless you know what the data is. Assuming a SHA-256 hash function, guessing the location of the data is wholly improbable as noted above (the likelihood is the same as guessing a 256-bit key). Partial data does not give any knowledge of the location of the data provided a good hash function is used, i.e. every extra byte assumes a radically different resulting hash.

It is important to be mindful that this security is not upheld when all useful hashes are published to a public blockchain. The underlying encryption remains the only barrier, which does not exist if someone has a suitable re-encryption key.

\subsection{Scalability}

As a proof of concept, scalability is of a lesser priority. At present, the use of IPFS and local nodes provide no immediate scalability issues~\footnote{Given that IPFS requires no consensus to be formed on object references in the distributed web.}. The compute layer, Ethereum, is the main barrier to any scalability.

Ethereum is intended as a platform for autonomous financial instruments. It's use as an application backbone in this project is clearly in conflict with it's intended purpose. Ethereum, on it's main network, has an aim of processing transactions within 15 seconds on average. If we assume that 1000 users are connected and interacting on the network, and there are therefore 1000 storage contracts, it is trivial to understand how the network could be flooded with transactions which it is unable to process is a suitable time period, particularly given this application and it's contracts are one of many.

\subsection{Development Stage}

Without considering the specifics of the accompanying implementation to this thesis, we evaluate the state of the project's development and how this reflects in its usability at present. The current barriers to entry are the nodes that a user must run locally for the system to function.

\begin{itemize}
  \item IPFS node
  \item Ethereum node
  \item Proxy Re-encryption node
\end{itemize}

As discussed, the proxy re-encryption node will cease to exist in future as the library required to perform encryption/re-encryption/decryption becomes available for client-side use. A Java client would make this possible now.

Dependency on a local IPFS node will be removed should the application choose to provide global IPFS nodes where users can add data~\footnote{Reading data does not require a local IPFS node as this can be handled by the IPFS gateway, https://gateway.ipfs.io.}. Alternatively, the ability to use a lightweight IPFS node as part of the client process would alleviate this issue.

The most significant barrier to entry comes from the dependency on a local Ethereum node. The alternative to this is to run a Mist browser or to use the Metamask extension to a current browser. The former is an entirely different browser environment and requires the user to move way from the environment they currently choose to work in. The latter requires the user to be using a suitable browser, and be using that browser on a device that is compatible with the installation of extensions. Metamask allows anyone to connect to live networks globally.
