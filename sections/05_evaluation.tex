\section{Evaluation}

\subsection{Technical}

\subsubsection{Key safety}

At the heart of the security model of this application lies the underlying security of Ethereum's (and more generally blockchain) security model and the security of the cryptography scheme used for encryptions.

\paragraph{User-held keys}

A fundamental issue with creating a decentralised system, certainly under the proposed implementation, is the issue of private key storage. Without a central authority managing the identities within the system each user is expected to securely store their keys. Failure to do so will result in account compromises possibly including corruption of data, changing of permissions, and taking control of an identity's contract. Owing to the transaction history available through a blockchain, previous data references are recoverable in the event of a compromise.

However, if a user loses either of their keys (identity or encryption) there are serious consequences.

If a user loses their identity key, it is impossible to prove that they own the address. This means that they would no longer have any control over their contract(s) with current permissions remaining and irrevokable. The user would not be able to share any further content or upload any references to content that they owned. Only a local (non-blockchain) record of all their data references would allow them to retrieve their data.

At this point I consider a possible solution to the problem of losing the identity key. If a future implementation allowed the user to delegate certain identities as privileged on their contract(s) it might be possible to regain access. These privileged identities would be able to form a quorum which would allow the transfer of a contract's properties to another, new, contract with a new identity. The practical implementation of this would be difficult, and it is likely that the transaction history of the original contract could not be maintained by the new contract.

If a user loses their encryption key, they are unable to directly decrypt data. With the implementation proposed there is no mechanism for them to recover their data other than through collusion with other identities with whom they have shared their data. Taking a similar stance to the identity key loss problem above, creating backup encryption keys which are given full access to the data in one's contract, and allowing the use of these under a quorum of privileged users would be a possible solution to the encryption key loss problem. In this scenario, there is a slight security loss, but this is negligible in practice.

\paragraph{Identity Spoofing}

Under the current implementation, access to one's storage contracts or group contracts are determined by the identity of their key. Every account (address) on an Ethereum network is a 20 byte value. These 20 bytes represent the last 20 bytes of the SHA-3 (Keccak) hash of the public key of the account holder. This public key is the counterpart to a 256-bit ECDSA private key which is used to unlock the account and sign transactions. An example of this derivation is found in table \ref{table:ethereum_ecdsa_address_derivation}.

\input{figures/ethereum_ecdsa_address_derivation}

The major concern for this system is identity spoofing. If a party has access to the private key associated with a specific ethereum address

Given that the ethereum address associated with any private key is 20 bytes, this gives $2^{160}$ possible addresses in the system. This means the probability of
guessing your address is extremely low ($6.8 \times 10^{-49}$). Whilst an identity's address can be public, this in itself provides a layer of obscurity.

With the public key is hashed, unless the user chooses reveal it, the public key remains private under the security provided by the given hash function. Therefore, no attacker gains (with respect to the challenge of acquiring the private key associated with an address) from knowing your address.

The 256-bit private key provides the main layer of security for an identity. With $2^{256}$ possible key values, the challenge of determining the private key corresponding to a public key (or identity's address) is hard. For each key possibility, the key must be used to generate a public key, which is hashed and the last 20 bytes compared. This is what will be referred to as a key check. Using a python script~\footnote{10,000 iterations of checking a private key against an address. Uses script in program code \ref{code:secp256k1_benchmark} (Appendix)} on a modern laptop~\footnote{MacBook Pro 13-inch. OS X 10.12.5. Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz. 8GB RAM.} with floating point performance of the order of 3.46 GFLOPS/s per core, a rate of 120 key checks per second can be achieved. On average $2^{255}$ tries will be required to produce the correct key.

$$
2^{255} \div (120 \times 3600 \times 24 \times 365) = 1.53 \times 10^{67} \text{ years}
$$

As of June 2016, the fastest supercomputers in the world have a potential of roughly 100 PFLOPS ($10^8$ GFLOPS)~\footnote{China builds world's fastest supercomputer.  \href{http://www.computerworld.com/article/3085483/high-performance-computing/china-builds-world-s-fastest-supercomputer-without-u-s-chips.html}{\textit{Computer World}}}. Even so, using current chipsets it would still take $10^{59}$ years to find the private key.

$$
1.53 \times 10^{67} \div (10^8 \div 3.46) = 5.29 \times 10^{59} \text{ years}
$$

Whilst computed using commodity hardware and an unoptimised script, the calculations shown illustrate the difficulty of determining and checking a 256-bit ECDSA (secp256k1) key against a known Ethereum address.

\paragraph{Breaking Data Encryption}

Stored on IPFS, the so-called 'permanent web', the quality of the encryption of personal data is of pivotal importance. The scheme uses a randomly generated symmetric key to encrypt the underlying data, which is itself encrypted by a user-specific public key. In this regard, a malicious attacker would have to either find the symmetric key or find the public key that unlocks the encrypted symmetric key. These challenges are defined by the security of the cryptography scheme and the key size used. For this project a 256-bit AES key and a 256-bit ElGamal key.

We assume that the underlying encryption is secure and that vulnerabilities are concerned with key leaks. This means that we do not consider cryptographic 'breaks', only that a key is found by brute force.

Fundamentally, there are $2^{256}$ possible keys to check against either the symmetric or asymmetric cryptography schemes. Assuming no information is given away by the public key of the asymmetric scheme, both schemes are equally secure requiring $2^{255}$ or $~5.8 \times 10^{76}$ trials to determine the key on average. Assuming a supercomputer has 100 petaflops and that this is a suitable measure of performance, it can generate $10^{17}$ keys per second. It will take $1.84 \times 10^{52}$ years on average to generate a suitable key for an encryption under a 256-bit scheme~\footnote{Not including the time taken to perform a decryption on a suitably small test encryption.}.

$$
\begin{aligned}
  10^{17} \times 3.6 \times 10^{3} \times 24 \times 365 &=& 3.1536 \times 10^{24} \text{ keys per year} \\
  \frac{2^{255}}{3.1536 \times 10^{24}} &=& 1.84 \times 10^{52} \text{ years}
\end{aligned}
$$

\subsubsection{Non-transitivity of a Re-encryption scheme}

In order to facilitate giving permissions to other parties the scheme only uses second-level encryptions. The most significant security implication of using second-level encryptions instead of a first-level encryption is that of re-encryption and delegation. With a second-level encryption, since the underlying data is encrypted using a public key, a suitable pairing and a suitable re-encryption key provides the means for any second-level encryption to be re-encrypted as a first-level encryption. Since a first-level encryption uses a bi-linear pairing of keys to encrypt the underlying data, this is not re-pairable and as such re-encryption cannot be performed. Given that a second-level encryption can be re-encrypted to a first-level encryption, and that a first-level encryption is not re-encryptable, the AFGH scheme used is shown to be non-transitive.

Non-transitivity is an extremely important property of this scheme. An entity $A$ encrypts their data $d$ with their public key such that it becomes $d_A$. $A$ produces a re-encryption key $re_{A \rightarrow B}$ for some other entity $B$. $B$ has previously created a re-encryption key $re_{B \rightarrow C}$ such that another entity $C$ is able to read their data. We assume both re-encryption keys are public, or at least both available to $C$ (possibly through collusion with the proxy). With a transitive scheme, entity $C$ would be able to use $re_{A \rightarrow B}$ and $re_{B \rightarrow C}$ to re-encrypt any $d_A$ to $d_C$, bypassing the permission of $A$ entirely.

In the non-transitive scheme, revealing $re_{A \rightarrow B}$ to $C$ bears no security implication. Whilst $C$ is able to create a first-level encryption for $B$, $C$ is none-the-wiser to the underlying data that $A$ has encrypted in $d_A$.

\subsubsection{Data security given public re-encryption keys}

Having considered why re-encryption keys can be public in terms of the security of single data blobs, we must evaluate the effects of this over multiple data blobs.

One criticism of the implemented scheme is that should an identity $I$ have read access to a storage contract owner's file $F_A$, they have the means to read any of said storage contract owner's files encrypted under the same key. They achieve this by finding a reference to the file they wish to read and, using the re-encryption key $re_{\text{SCO} \rightarrow \text{I}}$ that they already possess, they are able to re-encrypt the file into a first-level encryption under their own public key.

It is my opinion that this is one of the greatest flaws of the project's current implementation and represents a challenge in terms of resolution. Assuming that proxy re-encryption is secure and allows public re-encryption keys for singular stores, expanding this over multiple stores or stores with multiple data blobs might imply that a separate key is required for each data blob. If this is the case, the storage required to store keys and the responsibility on the user at a practical level makes for an application unlikely to succeed.

Crucially, a user of the application doesn't not want to hold their own keys. The application enforces that they must hold at least two keys (identity and encryption keys) for the system to function. Any need for a user to hold more keys than this is a problem. At present, there is no way to store secrets within the public blockchain, and with this restriction the security implications as discussed above are likely to remain in a completely decentralised system.

\subsubsection{The need for a proxy}

As the name would suggest proxy re-encryption is designed to be used by three parties, Alice, Bob, and a semi-trusted proxy. The role of the proxy is to perform re-encryption. Given that the AFGH scheme is both collusion-safe and non-transitive, we must consider the benefit that a proxy would give us, and also the compromise it requires.

Firstly, it's easy to see that the requirement of a proxy, a centralised service no less, somewhat inhibits the idea of a fully decentralised system. In fact, if a proxy is required for read access by every party other than the storage contract owner, then should the proxy cease to exist or be inoperable, access is denied to all persons other than the storage contract owner. Given the use case of the NHS, this might imply that doctors would be unable to access patient records or other data when a denial of service attack is taking place.

It is important to note that a denial of service on a blockchain is not impossible, and in fact flooding the network with transactions has this effect. It is however less potent since the compute power is distributed across many hundreds and thousands of completely independent nodes.

Considering the benefits of a proxy, a system whereby the proxy is authenticated and authorised with special privileges stops the re-encryption key (and the encrypted, stored data) from needing to exist publicly. Such a proxy would be authorised to perform re-encryption and check the permissions of an identity against a storage contract. The proxy would take a request from an identity, and assuming they had the necessary permissions and provided sufficient proof-of-identity, would return the requested data as a first-level encryption under the identity's public key. By performing in this way the proxy would prevent the re-encryption key or the storage reference ever being revealed and therefore removes the issue presented above with regards to overuse of the re-encryption key.

\paragraph{Is re-encryption possible client-side?}

Through the project a difficult choice had to be made. It was possible to use a scheme predating the AFGH scheme such as the scheme authored by \cite{bbs:1998:book}, rather than using the AFGH scheme for which there is no suitable javascript implementation. However, in using such a scheme, the security properties of the AFGH scheme would be lost, rendering the implementation of the project old fashioned and out of date before it could be improved. Instead of using an unsuitable scheme, an API which, at present, must be run on the client device was implemented using the existing Java library.

The use of this API is a key barrier to the decentralisation and global adoption across devices and should be thought of as a major issue. However, it also allowed the conclusion of a successful investigation into the project viability. An implementation of a client-side (likely JavaScript) library is required for future iterations.

\paragraph{Alternatives to proxy re-encryption}

\subsubsection{Ethereum as a blockchain candidate}

\subsubsection{Privacy of contract information and state}

Since this project's core goal is to reinstate the privacy so many honest actors in society have lost through corporate activity, it would be irresponsible to conclude without discussing the public nature of all data placed on Ethereum. Using any public, and permission-less, blockchain technology implies that all transactional data is exposed and made public. Program code \ref{code:view_storage_data} (Appendix) shows this by creating a contract, setting a value, and then exposing that value through a transaction.

Clearly the nature of data being public implies that one can be tracked through their transactions. For our purposes, this transparency exposes corporations interacting with the blockchain. Whether it benefits individuals overall or not is ambiguous. However, the privacy of the underlying data exchanged on a blockchain doesn't have to be compromised, provided no actual data itself is stored on the blockchain in an unencrypted form. Furthermore, only providing references on the blockchain implies that the permissions associated with a given data blob are decided, to some extent, off the chain and there is little to no benefit to having the reference public (to an attacker or scraper).

\subsubsection{Monetisation}

\subsubsection{Security by obscurity}

\subsection{Scalability}

\subsection{Development Stage}
